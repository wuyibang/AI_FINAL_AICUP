{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport glob\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nimport PIL\nimport random\nfrom PIL import Image\nimport json\n\n!pip install segmentation-models-pytorch --quiet\n!pip install -U albumentations --quiet\n\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset as BaseDataset\nimport torch.nn.functional as F\n\nimport torch\nimport numpy as np\nimport segmentation_models_pytorch as smp\nfrom torch import nn","metadata":{"id":"SUET7f53GSaI","execution":{"iopub.status.busy":"2022-06-12T10:05:15.175566Z","iopub.execute_input":"2022-06-12T10:05:15.176009Z","iopub.status.idle":"2022-06-12T10:05:34.414648Z","shell.execute_reply.started":"2022-06-12T10:05:15.175963Z","shell.execute_reply":"2022-06-12T10:05:34.413659Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"_dUNR6XmiQMs","outputId":"e57123dd-c39e-4a26-f546-68e18de939cd","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/content/drive')","metadata":{"id":"Yc65cmW3GcZE","outputId":"2f23d7d5-3ed5-44f4-d862-a660decfca22","execution":{"iopub.status.busy":"2022-06-12T10:05:34.416605Z","iopub.execute_input":"2022-06-12T10:05:34.417013Z","iopub.status.idle":"2022-06-12T10:05:34.421290Z","shell.execute_reply.started":"2022-06-12T10:05:34.416974Z","shell.execute_reply":"2022-06-12T10:05:34.420543Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"# DATA_DIR_train = \"/content/drive/MyDrive/Colab Notebooks/AI_final_proj/Train_Images/\"  #training\n# DATA_DIR_mask = \"/content/drive/MyDrive/Colab Notebooks/AI_final_proj/Train_Masks/\" #training\n\n# DATA_DIR_train = \"AI_final_proj/Train_Images/\"  #training\n# DATA_DIR_mask = \"AI_final_proj/Train_Masks/\" #training\n\nDATA_DIR_train = \"../input/ai-final-dataset/AI_final_proj/Train_Images\"  \nDATA_DIR_mask = \"../input/ai-final-dataset/AI_final_proj/Train_Masks\" \n\n# DATA_DIR_vail = '/data/home/VGH_Seg_IMG_Label/Valid'\n# DATA_DIR_test = '/data/home/VGH_Seg_IMG_Label/Test'\n\n# SavePath = \"AI_final_proj/model_exp_final/\"\nSavePath = \"./\"","metadata":{"id":"DmxZJf_ZGSaJ","execution":{"iopub.status.busy":"2022-06-12T10:05:34.422519Z","iopub.execute_input":"2022-06-12T10:05:34.423128Z","iopub.status.idle":"2022-06-12T10:05:34.431523Z","shell.execute_reply.started":"2022-06-12T10:05:34.423092Z","shell.execute_reply":"2022-06-12T10:05:34.430664Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"RESIZE_SIZE = 32*20\nBATCH_SIZE = 3\nNUM_WORKERS = 2\n\nENCODER = 'efficientnet-b1'\nENCODER_WEIGHTS = 'imagenet'\nCLASSES = ['stas']\nACTIVATION = 'sigmoid' \nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nEPOCHS = 30\n\nSEED = 1187\n\nDEVICE","metadata":{"id":"7FZRB_z4-dYn","execution":{"iopub.status.busy":"2022-06-12T10:05:34.435914Z","iopub.execute_input":"2022-06-12T10:05:34.436496Z","iopub.status.idle":"2022-06-12T10:05:34.445180Z","shell.execute_reply.started":"2022-06-12T10:05:34.436468Z","shell.execute_reply":"2022-06-12T10:05:34.444270Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\nseed_everything(SEED)","metadata":{"execution":{"iopub.status.busy":"2022-06-12T10:05:34.447760Z","iopub.execute_input":"2022-06-12T10:05:34.448651Z","iopub.status.idle":"2022-06-12T10:05:34.454707Z","shell.execute_reply.started":"2022-06-12T10:05:34.448616Z","shell.execute_reply":"2022-06-12T10:05:34.453862Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"ids = os.listdir(DATA_DIR_train)\n# print(ids)\n# print(len(ids))","metadata":{"id":"QjO2uVgiXcPj","outputId":"35fe64a7-fc0d-4ef4-910d-7cb7d245e251","execution":{"iopub.status.busy":"2022-06-12T10:05:34.456672Z","iopub.execute_input":"2022-06-12T10:05:34.459729Z","iopub.status.idle":"2022-06-12T10:05:34.465200Z","shell.execute_reply.started":"2022-06-12T10:05:34.459595Z","shell.execute_reply":"2022-06-12T10:05:34.464405Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"images_list = [os.path.join(DATA_DIR_train, image_id) for image_id in ids]\n# display(images_list)\nprint(len(images_list))\nmasks_list = [os.path.join(DATA_DIR_mask, mask_id) for mask_id in ids]\n# display(masks_list)\nprint(len(masks_list))","metadata":{"id":"Q2ovGEoJXnhz","outputId":"ccfb79d6-43e3-4fed-d869-d26778d57d49","execution":{"iopub.status.busy":"2022-06-12T10:05:34.466895Z","iopub.execute_input":"2022-06-12T10:05:34.467490Z","iopub.status.idle":"2022-06-12T10:05:34.478249Z","shell.execute_reply.started":"2022-06-12T10:05:34.467452Z","shell.execute_reply":"2022-06-12T10:05:34.477426Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"for i in range(len(masks_list)):\n  masks_list[i] = masks_list[i].replace('.jpg','.png')\n# display(masks_list)","metadata":{"id":"5iQ0mertfjvU","execution":{"iopub.status.busy":"2022-06-12T10:05:34.479814Z","iopub.execute_input":"2022-06-12T10:05:34.480388Z","iopub.status.idle":"2022-06-12T10:05:34.486477Z","shell.execute_reply.started":"2022-06-12T10:05:34.480330Z","shell.execute_reply":"2022-06-12T10:05:34.485649Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"\nx_train, x_valid, y_train, y_valid = train_test_split(images_list, masks_list, test_size=0.2, random_state=SEED)\nx_valid, x_test, y_valid, y_test = train_test_split(x_valid, y_valid, test_size=0.5, random_state=SEED)\n","metadata":{"id":"Hth89NVBXRvC","execution":{"iopub.status.busy":"2022-06-12T10:05:34.487841Z","iopub.execute_input":"2022-06-12T10:05:34.488533Z","iopub.status.idle":"2022-06-12T10:05:34.497221Z","shell.execute_reply.started":"2022-06-12T10:05:34.488480Z","shell.execute_reply":"2022-06-12T10:05:34.496429Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"print(len(x_train))\nprint(len(y_train))\nprint(len(x_valid))\nprint(len(y_valid))\nprint(len(x_test))\nprint(len(y_test))","metadata":{"id":"gKIzirtdY-j-","outputId":"68da6e38-28c1-4aa8-dc24-1800a09c555a","execution":{"iopub.status.busy":"2022-06-12T10:05:34.501018Z","iopub.execute_input":"2022-06-12T10:05:34.501269Z","iopub.status.idle":"2022-06-12T10:05:34.505991Z","shell.execute_reply.started":"2022-06-12T10:05:34.501246Z","shell.execute_reply":"2022-06-12T10:05:34.505050Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"# y_train\n# # cv2.imread(x_train[0])\n# cv2.imread(y_train[0], 0)","metadata":{"id":"lqIhJvGRdIyt","outputId":"34205ff9-cfb2-42b2-a75d-b1684fad43af","execution":{"iopub.status.busy":"2022-06-12T10:05:34.507201Z","iopub.execute_input":"2022-06-12T10:05:34.507723Z","iopub.status.idle":"2022-06-12T10:05:34.513199Z","shell.execute_reply.started":"2022-06-12T10:05:34.507687Z","shell.execute_reply":"2022-06-12T10:05:34.512390Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"# helper function for data visualization\ndef visualize(**images):\n    \"\"\"PLot images in one row.\"\"\"\n    n = len(images)\n    plt.figure(figsize=(16, 16))\n    for i, (name, image) in enumerate(images.items()):\n        plt.subplot(1, n, i + 1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.title(' '.join(name.split('_')).title())\n        plt.imshow(image)\n    plt.show()","metadata":{"id":"hVXlJRMAGSaL","execution":{"iopub.status.busy":"2022-06-12T10:05:34.514639Z","iopub.execute_input":"2022-06-12T10:05:34.515626Z","iopub.status.idle":"2022-06-12T10:05:34.523669Z","shell.execute_reply.started":"2022-06-12T10:05:34.515589Z","shell.execute_reply":"2022-06-12T10:05:34.522707Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"# from torch.utils.data import DataLoader\n# from torch.utils.data import Dataset as BaseDataset\n# import torch.nn.functional as F","metadata":{"id":"kmfzSgFaGSaL","execution":{"iopub.status.busy":"2022-06-12T10:05:34.524930Z","iopub.execute_input":"2022-06-12T10:05:34.525785Z","iopub.status.idle":"2022-06-12T10:05:34.533696Z","shell.execute_reply.started":"2022-06-12T10:05:34.525732Z","shell.execute_reply":"2022-06-12T10:05:34.532923Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"\nclass Dataset(BaseDataset):\n    \"\"\"CamVid Dataset. Read images, apply augmentation and preprocessing transformations.\n    \n    Args:\n        images_dir (str): path to images folder\n        masks_dir (str): path to segmentation masks folder\n        class_values (list): values of classes to extract from segmentation mask\n        augmentation (albumentations.Compose): data transfromation pipeline \n            (e.g. flip, scale, etc.)\n        preprocessing (albumentations.Compose): data preprocessing \n            (e.g. noralization, shape manipulation, etc.)\n    \n    \"\"\"\n    \n    CLASSES = ['bg', 'stas']\n    \n    def __init__(\n            self, \n            images_list, \n            masks_list, \n            classes=None, \n            augmentation=None, \n            preprocessing=None,\n    ):\n        # self.ids = os.listdir(images_dir)\n        # self.images_fps = [os.path.join(images_dir, image_id) for image_id in self.ids]\n        # self.masks_fps = [os.path.join(masks_dir, image_id) for image_id in self.ids]\n        \n        self.images_fps = images_list\n        self.masks_fps = masks_list\n        \n        # convert str names to class values on masks\n        self.class_values = [self.CLASSES.index(cls.lower()) for cls in classes]\n        \n        self.augmentation = augmentation\n        self.preprocessing = preprocessing\n    \n    def __getitem__(self, i):\n        \n        # read data\n        # self.masks_fps[i] = self.masks_fps[i].replace('.jpg','.png')\n        image = cv2.imread(self.images_fps[i])\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        if image.shape != (RESIZE_SIZE, RESIZE_SIZE, 3):\n            image = cv2.resize(image, (RESIZE_SIZE, RESIZE_SIZE), interpolation=cv2.INTER_LANCZOS4)\n        \n        mask = cv2.imread(self.masks_fps[i], 0)\n        if mask.shape != (RESIZE_SIZE, RESIZE_SIZE, 3):\n            mask = cv2.resize(mask, (RESIZE_SIZE, RESIZE_SIZE), interpolation=cv2.INTER_LANCZOS4)  \n        mask = mask.astype('bool')\n        \n        # extract certain classes from mask (e.g. cars)\n        masks = [(mask == v) for v in self.class_values]\n        mask = np.stack(masks, axis=-1).astype('float')\n        \n        # apply augmentations\n        if self.augmentation:\n            sample = self.augmentation(image=image, mask=mask)\n            image, mask = sample['image'], sample['mask']\n        \n        # apply preprocessing\n        if self.preprocessing:\n            sample = self.preprocessing(image=image, mask=mask)\n            image, mask = sample['image'], sample['mask']\n            \n        return image, mask\n        \n    def __len__(self):\n        return len(self.images_fps)","metadata":{"id":"vwxR8gtrGSaM","execution":{"iopub.status.busy":"2022-06-12T10:05:34.534921Z","iopub.execute_input":"2022-06-12T10:05:34.535563Z","iopub.status.idle":"2022-06-12T10:05:34.549519Z","shell.execute_reply.started":"2022-06-12T10:05:34.535528Z","shell.execute_reply":"2022-06-12T10:05:34.548786Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"# Lets look at data we have\n\ndataset = Dataset(images_list=images_list, \n                  masks_list=masks_list, \n                  classes=['stas'])\n\nimage, mask = dataset[4] # get some sample\nvisualize(\n    image=image, \n    stas_mask=mask.squeeze(),\n)","metadata":{"id":"go4TAyr8GSaM","outputId":"22e3c934-902b-4d30-fbb7-3a6733936cab","execution":{"iopub.status.busy":"2022-06-12T10:05:34.550895Z","iopub.execute_input":"2022-06-12T10:05:34.551639Z","iopub.status.idle":"2022-06-12T10:05:34.919248Z","shell.execute_reply.started":"2022-06-12T10:05:34.551589Z","shell.execute_reply":"2022-06-12T10:05:34.918567Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"print(image.shape)\nprint(mask.shape)","metadata":{"id":"EAWUi1CrM8sh","outputId":"a4e79a49-0737-4699-e3fc-45dffa7f886d","execution":{"iopub.status.busy":"2022-06-12T10:05:34.920599Z","iopub.execute_input":"2022-06-12T10:05:34.921480Z","iopub.status.idle":"2022-06-12T10:05:34.926202Z","shell.execute_reply.started":"2022-06-12T10:05:34.921445Z","shell.execute_reply":"2022-06-12T10:05:34.925476Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"mask.squeeze().shape","metadata":{"id":"MiF8bH5gODUK","outputId":"9119cae3-a0e0-4382-af96-240ce201c71a","execution":{"iopub.status.busy":"2022-06-12T10:05:34.927659Z","iopub.execute_input":"2022-06-12T10:05:34.928239Z","iopub.status.idle":"2022-06-12T10:05:34.936375Z","shell.execute_reply.started":"2022-06-12T10:05:34.928204Z","shell.execute_reply":"2022-06-12T10:05:34.935515Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"import albumentations as albu\n\ndef get_training_augmentation():\n    train_transform = [\n\n        albu.HorizontalFlip(p=0.5),\n        albu.Rotate(limit=40,p=1,border_mode=cv2.BORDER_CONSTANT),\n        albu.VerticalFlip(p=0.5),\n        albu.ShiftScaleRotate(scale_limit=0.5, rotate_limit=0, shift_limit=0.1, p=0.5, border_mode=cv2.BORDER_CONSTANT),\n        \n        albu.HueSaturationValue(p=0.6),\n        albu.Sharpen(p=0.5),\n        albu.RandomBrightnessContrast(p=0.4),\n\n        albu.Crop(x_min=0, y_min=0, x_max=RESIZE_SIZE, y_max=RESIZE_SIZE-40, p=0.5),\n        albu.PadIfNeeded(RESIZE_SIZE, RESIZE_SIZE)\n\n        \n    ]\n    return albu.Compose(train_transform)\n\ndef to_tensor(x, **kwargs):\n    return x.transpose(2, 0, 1).astype('float32')\n\n\ndef get_preprocessing(preprocessing_fn):\n    \"\"\"Construct preprocessing transform\n    \n    Args:\n        preprocessing_fn (callbale): data normalization function \n            (can be specific for each pretrained neural network)\n    Return:\n        transform: albumentations.Compose\n    \n    \"\"\"\n    \n    _transform = [\n        albu.Lambda(image=preprocessing_fn),\n        albu.Lambda(image=to_tensor, mask=to_tensor),\n    ]\n    return albu.Compose(_transform)","metadata":{"id":"ETSrDJK5GSaN","execution":{"iopub.status.busy":"2022-06-12T10:05:34.937935Z","iopub.execute_input":"2022-06-12T10:05:34.938625Z","iopub.status.idle":"2022-06-12T10:05:34.951166Z","shell.execute_reply.started":"2022-06-12T10:05:34.938588Z","shell.execute_reply":"2022-06-12T10:05:34.950316Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"#### Visualize resulted augmented images and masks\n\naugmented_dataset = Dataset(\n    images_list=images_list, \n    masks_list=masks_list, \n    augmentation=get_training_augmentation(), \n    classes=['stas'],\n)\n\n# same image with different random transforms\nfor i in range(3):\n    image, mask = augmented_dataset[1]\n    visualize(image=image, mask=mask.squeeze(-1))","metadata":{"id":"ew8uCoUsGSaO","outputId":"4e9e6e86-7baf-45a2-d967-bac9f09c9679","execution":{"iopub.status.busy":"2022-06-12T10:05:34.952559Z","iopub.execute_input":"2022-06-12T10:05:34.953263Z","iopub.status.idle":"2022-06-12T10:05:36.026310Z","shell.execute_reply.started":"2022-06-12T10:05:34.953226Z","shell.execute_reply":"2022-06-12T10:05:36.025576Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"markdown","source":"## Create model and train","metadata":{"id":"xam15UbnGSaP"}},{"cell_type":"code","source":"# import torch\n# import numpy as np\n# import segmentation_models_pytorch as smp\n# from torch import nn","metadata":{"id":"ws_sjj_0GSaQ","execution":{"iopub.status.busy":"2022-06-12T10:05:36.027561Z","iopub.execute_input":"2022-06-12T10:05:36.028263Z","iopub.status.idle":"2022-06-12T10:05:36.032235Z","shell.execute_reply.started":"2022-06-12T10:05:36.028226Z","shell.execute_reply":"2022-06-12T10:05:36.031605Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"\n# ENCODER = 'resnet50'\n# ENCODER_WEIGHTS = 'imagenet'\n# CLASSES = ['stas']\n# ACTIVATION = 'sigmoid' \n# DEVICE = 'cuda'\n# EPOCHS = 10\n\n\n\n# create segmentation model with pretrained encoder\nmodel = smp.DeepLabV3(\n    encoder_name=ENCODER, \n    encoder_weights=ENCODER_WEIGHTS, \n    classes=len(CLASSES), \n    activation=ACTIVATION,\n\n)\n\npreprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)","metadata":{"id":"1DyU1JV7GSaQ","execution":{"iopub.status.busy":"2022-06-12T10:05:36.033283Z","iopub.execute_input":"2022-06-12T10:05:36.034034Z","iopub.status.idle":"2022-06-12T10:05:36.237200Z","shell.execute_reply.started":"2022-06-12T10:05:36.033983Z","shell.execute_reply":"2022-06-12T10:05:36.235919Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"# train_dataset = Dataset(\n#     images_list=images_list, \n#     masks_list=masks_list,  \n#     augmentation=get_training_augmentation(), \n#     preprocessing=get_preprocessing(preprocessing_fn),\n#     classes=CLASSES,\n# )","metadata":{"id":"HHcTigRkQiXk","execution":{"iopub.status.busy":"2022-06-12T10:05:36.238816Z","iopub.execute_input":"2022-06-12T10:05:36.239213Z","iopub.status.idle":"2022-06-12T10:05:36.244431Z","shell.execute_reply.started":"2022-06-12T10:05:36.239173Z","shell.execute_reply":"2022-06-12T10:05:36.243469Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"train_dataset = Dataset(\n    x_train, \n    y_train, \n    augmentation=get_training_augmentation(), \n    preprocessing=get_preprocessing(preprocessing_fn),\n    classes=CLASSES,\n)\n\nvalid_dataset = Dataset(\n    x_valid, \n    y_valid, \n    preprocessing=get_preprocessing(preprocessing_fn),\n    classes=CLASSES,\n)\n\ntrain_loader = DataLoader(train_dataset, pin_memory=True, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\nvalid_loader = DataLoader(valid_dataset, pin_memory=True, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)","metadata":{"id":"G_KZ00CkGSaQ","execution":{"iopub.status.busy":"2022-06-12T10:05:36.245739Z","iopub.execute_input":"2022-06-12T10:05:36.246402Z","iopub.status.idle":"2022-06-12T10:05:36.256032Z","shell.execute_reply.started":"2022-06-12T10:05:36.246359Z","shell.execute_reply":"2022-06-12T10:05:36.255161Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"# Dice/F1 score - https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient\n# IoU/Jaccard score - https://en.wikipedia.org/wiki/Jaccard_index\n\nloss = smp.utils.losses.DiceLoss()\nmetrics = [\n    smp.utils.metrics.Fscore(threshold=0.5),\n]\n\noptimizer = torch.optim.Adam([ \n    dict(params=model.parameters(), lr=0.0001 , betas=(0.9, 0.999), eps=1e-08, weight_decay=0.0001, amsgrad=False),\n])","metadata":{"id":"IBY7Wj8BGSaR","execution":{"iopub.status.busy":"2022-06-12T10:05:36.257717Z","iopub.execute_input":"2022-06-12T10:05:36.259014Z","iopub.status.idle":"2022-06-12T10:05:36.268803Z","shell.execute_reply.started":"2022-06-12T10:05:36.258971Z","shell.execute_reply":"2022-06-12T10:05:36.267691Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"# model","metadata":{"execution":{"iopub.status.busy":"2022-06-12T10:05:36.270162Z","iopub.execute_input":"2022-06-12T10:05:36.271423Z","iopub.status.idle":"2022-06-12T10:05:36.275888Z","shell.execute_reply.started":"2022-06-12T10:05:36.271266Z","shell.execute_reply":"2022-06-12T10:05:36.274793Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()\ntorch.cuda.empty_cache()    ","metadata":{"id":"Md2bMRU9lHNL","execution":{"iopub.status.busy":"2022-06-12T10:05:36.277580Z","iopub.execute_input":"2022-06-12T10:05:36.278706Z","iopub.status.idle":"2022-06-12T10:05:37.025732Z","shell.execute_reply.started":"2022-06-12T10:05:36.278669Z","shell.execute_reply":"2022-06-12T10:05:37.024611Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"# create epoch runners \n# it is a simple loop of iterating over dataloader`s samples\ntrain_epoch = smp.utils.train.TrainEpoch(\n    model, \n    loss=loss, \n    metrics=metrics, \n    optimizer=optimizer,\n    device=DEVICE,\n    verbose=True,\n)\n\nvalid_epoch = smp.utils.train.ValidEpoch(\n    model, \n    loss=loss, \n    metrics=metrics, \n    device=DEVICE,\n    verbose=True,\n)\n\n","metadata":{"id":"D4Pkhma8GSaR","execution":{"iopub.status.busy":"2022-06-12T10:05:37.027919Z","iopub.execute_input":"2022-06-12T10:05:37.028314Z","iopub.status.idle":"2022-06-12T10:05:37.093196Z","shell.execute_reply.started":"2022-06-12T10:05:37.028275Z","shell.execute_reply":"2022-06-12T10:05:37.092433Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"path = SavePath\ncheckpoint = 'deeplab_effi_b1_50_aug.pth'\n# os.makedirs(path)","metadata":{"id":"8jfpXDODGSaR","execution":{"iopub.status.busy":"2022-06-12T10:05:37.097096Z","iopub.execute_input":"2022-06-12T10:05:37.097379Z","iopub.status.idle":"2022-06-12T10:05:37.102363Z","shell.execute_reply.started":"2022-06-12T10:05:37.097355Z","shell.execute_reply":"2022-06-12T10:05:37.101436Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"gc.collect()\ntorch.cuda.empty_cache()  ","metadata":{"execution":{"iopub.status.busy":"2022-06-12T10:05:37.103756Z","iopub.execute_input":"2022-06-12T10:05:37.104525Z","iopub.status.idle":"2022-06-12T10:05:37.299929Z","shell.execute_reply.started":"2022-06-12T10:05:37.104489Z","shell.execute_reply":"2022-06-12T10:05:37.299077Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"max_score = 0\n\ntrain_loss_list = []\ntrain_fscore_list = []\nvalid_loss_list = []\nvalid_fscore_list = []\n\nfor i in range(EPOCHS):\n    \n    print('\\nEpoch: {}'.format(i))\n    train_logs = train_epoch.run(train_loader)\n    valid_logs = valid_epoch.run(valid_loader)\n    train_loss_list.append(train_logs['dice_loss'])\n    train_fscore_list.append(train_logs['fscore'])\n    \n    valid_loss_list.append(valid_logs['dice_loss'])\n    valid_fscore_list.append(valid_logs['fscore'])\n    \n\n    if max_score < valid_logs['fscore']:\n        max_score = valid_logs['fscore']\n        torch.save(model, path+'/best_mode_unet_resnet50_aug.pth')\n        print('Model saved!')\n\n        \n#     if i == 35:\n#         optimizer.param_groups[0]['lr'] = 1e-5\n#         print('Decrease decoder learning rate to 1e-5!')","metadata":{"id":"z67ThrorGSaR","outputId":"5d660243-cb78-4de6-c798-001b0c730818","scrolled":true,"execution":{"iopub.status.busy":"2022-06-12T10:05:37.301653Z","iopub.execute_input":"2022-06-12T10:05:37.302075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(0)\nplt.plot(train_fscore_list)\nplt.plot(valid_fscore_list)\nplt.title('Train Logs')\nplt.ylabel('accuracy')\nplt.xlabel('Epoch')\nplt.legend(['train', 'validation'], loc='lower right')\n\nplt.figure(1)\nplt.plot(train_loss_list)\nplt.plot(valid_loss_list)\nplt.title('Train Logs')\nplt.ylabel('loss')\nplt.xlabel('Epoch')\nplt.legend(['train', 'validation'], loc='upper right')\n\n\nplt.show()","metadata":{"id":"4G1V7gOrGSaS","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load best saved checkpoint\nbest_model = torch.load(SavePath +'/'+'best_mode_unet_resnet50_aug.pth')","metadata":{"id":"CTyUB9VBGSaS","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# optimizer.param_groups[0]['lr']\nmax_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = Dataset(\n    x_test, \n    y_test, \n    preprocessing=get_preprocessing(preprocessing_fn),\n    classes=CLASSES,\n)\n\ntest_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=NUM_WORKERS)","metadata":{"id":"vrFodpHGGSaS","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# evaluate model on test set\ntest_epoch = smp.utils.train.ValidEpoch(\n    model=best_model,\n    loss=loss,\n    metrics=metrics,\n    device=DEVICE,\n)\n\nlogs = test_epoch.run(test_dataloader)","metadata":{"id":"ZLxyGKjTGSaT","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test dataset without transformations for image visualization\ntest_dataset_vis = Dataset(\n    x_test, y_test, \n    classes=CLASSES,\n)","metadata":{"id":"I0d77jO5GSaT","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"out_path= SavePath + \"/\" + \"out_dir\"\n# os.makedirs(out_path)","metadata":{"id":"imoiaJemGSaT","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfor i in range(len(test_dataset_vis)):\n    name = os.path.basename(test_dataset_vis.masks_fps[i])\n    print(name)\n    image_vis = test_dataset_vis[i][0].astype('uint8')\n    image, gt_mask = test_dataset[i]\n    x_tensor = torch.from_numpy(image).to(DEVICE).unsqueeze(0)\n    pr_mask = best_model.predict(x_tensor)\n    pr_mask = (pr_mask.squeeze().cpu().numpy().round())\n    len(pr_mask)\n#     print(gt_mask.shape)\n    zeros = np.zeros((RESIZE_SIZE, RESIZE_SIZE, 3))\n    zeros[...,0] = pr_mask\n    zeros = cv2.resize(zeros, (1920, 828))\n#     print(i)\n    visualize( \n            image=image_vis, \n            ground_truth_mask=gt_mask.transpose(1, 2, 0)[...,0], \n            predicted_mask=pr_mask\n        )\n#     plt.imshow(zeros)\n#     plt.show()\n#     print(os.path.join(out_path, name.replace('.jpg','.png')))\n#     plt.imsave(os.path.join(out_path, name.split.replace('.jpg','.png'), zeros))\n    ","metadata":{"id":"86_tGMZiGSaT","scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"ycVTTqWlGSaU"},"execution_count":null,"outputs":[]}]}